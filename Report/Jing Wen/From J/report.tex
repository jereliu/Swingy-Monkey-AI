\documentclass[11pt]{article}

%formating author affiliation
\usepackage{authblk}
\author[1]{(Jeremiah) Zhe Liu}
\author[2]{(Vivian) Wenwan Yang}
\author[1]{Jing Wen}
\affil[1]{Department of Biostatistics, Harvard School of Public Health}
\affil[2]{Department of Computational Science and Engineering, SEAS}

% change document font family to Palatino, and code font to Courier
\usepackage{mathpazo} % add possibly `sc` and `osf` options
\usepackage{eulervm}
\usepackage{courier}
%allow formula formatting

%identation in nested enumerates
\usepackage[shortlabels]{enumitem}
\setlist[enumerate,1]{leftmargin=1cm} % level 1 list
\setlist[enumerate,2]{leftmargin=2cm} % level 2 list

%flush align equations to left, this also loads amsmath 
%\usepackage[fleqn]{mathtools}
\usepackage{mathtools}
\usepackage{amsthm}
\DeclareMathAlphabet\mathbfcal{OMS}{cmsy}{b}{n}
\usepackage{comment}

%declare math symbolz
%# inner product
\DeclarePairedDelimiter{\inner}{\langle}{\rangle}

%declare argmin
\newcommand{\argmin}{\operatornamewithlimits{argmin}}

%declare checkmark
\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%

%title positon
\usepackage{titling} %fix title
\setlength{\droptitle}{-6em}   % Move up the title 

%change section title font size
\usepackage{titlesec} 
\titleformat{\section}
  {\normalfont\fontsize{12}{15}}{\thesection}{1em}{}
\titleformat{\subsection}
  {\normalfont\fontsize{12}{13}}{\thesubsection}{1em}{}
\titleformat{\subsubsection}
  {\normalfont\fontsize{12}{13}}{\thesubsubsection}{1em}{}

%overwrite bfseries to allow formula in section title  
\def\bfseries{\fontseries \bfdefault \selectfont \boldmath}

% change page margin
\usepackage[margin=0.8 in]{geometry} 

%disable indentation
\setlength\parindent{0pt}

%allow inserting multiple graphs
\usepackage{graphicx}
\usepackage[skip=1pt]{subcaption}
\usepackage[justification=centering,font=small]{caption}
\newcommand{\indep}{\rotatebox[origin=c]{90}{$\models$}}%indep sign

%allow code chunks
\usepackage{listings}
%\lstset{basicstyle=\footnotesize\ttfamily,breaklines=true}
\lstset{basicstyle=\footnotesize\ttfamily,breaklines=true}
\lstset{frame=lrbt,xleftmargin=\fboxsep, xrightmargin=-\fboxsep}
\lstset{language=R, commentstyle=\bfseries, 
keywordstyle=\ttfamily} %R-related formatting
\lstset{escapeinside={<@}{@>}}

%allow merged cell in tables
\usepackage{multirow}

%allow http links
\usepackage{hyperref}

%allow different font colors
\usepackage{xcolor}

%Thm and Def environment
\theoremstyle{definition}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}

\newenvironment{definition2}[1][Definition]{\begin{trivlist} %def without index
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}

\newenvironment{example}[1][Example]{\begin{trivlist} %def without index
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}


%macros from Bob Gray
\usepackage{"./macro/GrandMacros"}
\usepackage{"./macro/Macro_BIO235"}

\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%% TItle page with contents %%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{\textbf{CS 181 Machine Learning}\\ 
\textbf{Practical 4 Report, Team \textit{la Derni\`{e}re Dame M}}}

\pretitle{\begin{centering}\Large}
\posttitle{\par\end{centering}}

\date{\today}
\vspace{-10em}
\maketitle
\vspace{-2em}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%% Formal Sections %%%%% %%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{\textbf{Exploratory Analysis}}\label{sec:EDA}


\section{\textbf{Method}}

\subsection{\textbf{Rationale on Model Choice}}

\subsection{\textbf{Estimation}}\label{sec:estimation}
\subsubsection{SVM}
The SVM maps the input vectors into high-dimensional feature space and returns the maximum margin hyper plane. SVM algorithm with a linear kernal could be implemented by constructing the following problem:
$$min_{r,w,b}\dfrac{1}{2}||w||^2$$
$$s.t. y^{(i)T}\big(w^Tx^{(i)}+b\big)\geq1, i=1...n$$
Data:\\
The SVM is implemented in a static tree trunk setting, and only the first tree ahead of the monkey is considered. Given the command to jump, the current state is labeled as 1, otherwise current state is labeled as -1. Hence at each step, the training set includes a current state $x^{(i)}=['vel','top','bot']=[\Delta x,\Delta y,\Delta z]$ and related label $y^{(i)}\in \{-1,1\} $.\\

We can then choose a high-dimension feature space. For the below example, nine features from fundamental analysis are selected by adding second and third order of the feature.
$$\boldsymbol{\Phi} = \big[\Delta x,\Delta y,\Delta z, \Delta x^2,\Delta y^2,\Delta z^2,\Delta x^3,\Delta y^3,\Delta z^3 \big]$$ 
$$k(x,z) = \boldsymbol{\Phi}^T\boldsymbol{\Phi}$$
\subsubsection{Model-based estimation}
\textbf{ Optimization Algorithm}\\
Value iteration could be implemented in order to find the value function for small MDPs. The value iteration is illustrated as follows:\\

For each state, initialize $V(s):=0$.\\
Repeat until converge\\
$\{$For each state:
$$V(s) = R(s) + \max\limits_{a\in A}\gamma\sum_{s'}P(s'|s,a)V(s')$$
$\}$\\

After $V(s)$ and $P_{sa}$ were learnt by the above algorithm, the optimal $a$ is given by:
$$a^* = \max\limits_{a\in A}P(s'|s,a)V(s)$$
\subsubsection{Q-learning}
\subsubsection{exploitation vs. exploration}
$e = 0.001$

$\epsilon = \frac{e}{k}$

$k$ = \# of actions taken from state s

\subsection{\textbf{Numerical Challenges \& Further Modification}}

\subsubsection{Parameter Selection}
why $\gamma = 0.95$
$\alpha = 1/k$
\newpage
\section{\textbf{Discussion \& Possible Directions}}


\newpage
\section*{\textbf{Reference}}
\begin{enumerate}
\item \label{ref:handbook}
Ricci F, Rokach L, Shapira B et al. (2010) \textbf{Recommender Systems Handbook}. \textit{Springer}. 
\item \label{ref:MFieee}
Koren Y, Bell R, Volinsky C. (2009) \textbf{Matrix factorization techniques for recommender systems}. \textit{IEEE Computer} Aug 2009, 42-49. 
\item \label{ref:WLA}
Srebro N,  Jaakkola T.(2003) \textbf{Weighted low-rank approximations}. \textit{Proceedings of the Twentieth International Conference} 720â€“727.
\item \label{ref:PMF}
R Salakhutdinov, A Mnih. (2008) \textbf{Probabilistic Matrix Factorization}. \textit{Advances in Neural Information Processing Systems} Vol. 20

\item \label{ref:implicit}
Koren, Y. (2008) \textbf{Factorization Meets the Neighborhood: a Multifaceted Collaborative Filtering Model}, \textit{Proc. 14th ACM SIGKDD International Conference on Knowledge Discovery and
Data Mining}.

\end{enumerate}

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
